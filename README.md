# Communication-Department-Network
Network build out for communication department


## Automated ELK Stack Deployment

The files in this repository were used to configure the network depicted below.

communications_department_network_diagram.gliffy

These files have been tested and used to generate a live ELK deployment on Azure. They can be used to either recreate the entire deployment pictured above. Alternatively, select portions of the Communication-Department-Network file may be used to install only certain pieces of it, such as Filebeat.

Communication-Department-Network/LInux/My-Playbook.txt

This document contains the following details:
- Description of the Topology
- Access Policies
- ELK Configuration
  - Beats in Use
  - Machines Being Monitored
- How to Use the Ansible Build


### Description of the Topology

The main purpose of this network is to expose a load-balanced and monitored instance of DVWA, the D*mn Vulnerable Web Application.

Load balancing ensures that the application will be highly efficient in distributing incoming data to the network, in addition to restricting unwanted access to the network. Load balancers protect the boarders of the private network. While using a jump box to access the network adds even more protection. The jump box minimizes the point of entry for the private network and therefore minimizes the security risk’s involved.

Integrating an ELK server allows users to easily monitor the vulnerable VMs for changes to the log files and system up time. Filebeat collects data about the file system and ships the files directly to the elk stack. Metricbeat records machine metrics such as uptime, essentially monitoring the health of your servers.

The configuration details of each machine may be found below.

| Name           | Funtion    | IP Address | Operating System |

|----------------|------------|------------|------------------|

| USComDepJB1    | Gateway    | 10.0.0.5   | Linux            |

| DVM1z1         | Web Server | 10.0.0.6   | Linux            |

| DVM2z1         | Web Server | 10.1.0.4   | Linux            |

| USComElkserver | Elk server | 10.0.0.7   | Linux            |



### Access Policies

The machines on the internal network are not exposed to the public Internet.

Only the UsComElkserver machine can accept connections from the Internet. Access to this machine is only allowed from the following IP addresses: 10.0.0.5

Machines within the network can only be accessed by USComDepJB1.

A summary of the access policies in place can be found in the table below.


| Name           | Publicly Accessible | Allowed IP Address          |
|----------------|---------------------|-----------------------------|
| USComDepJB1    | Yes                 | 10.0.0.5 and 67.191.172.177 |
| DVM1z1         | No                  | 10.0.0.5                    |
| DVM2z1         | No                  | 10.0.0.5                    |
| USComElkselver | No                  | 10.0.0.5                    |
 


### Elk Configuration

Ansible was used to automate configuration of the ELK machine. No configuration was performed manually, which is advantageous because it can help deploy applications more efficiently.  

The playbook implements the following tasks:

- Install docker

- Install python

- Install docker module
- Ran command to increase virtual memory
- Install and launch sebp/elk docker web container

The following screenshot displays the result of running `docker ps` after successfully configuring the ELK instance.

![TODO: Update the path with the name of your screenshot of docker ps output](Images/docker_ps_output.png)

### Target Machines & Beats
This ELK server is configured to monitor the following machines:
- 10.0.06 and 10.1.0.4

We have installed the following Beats on these machines:

Filebeats and Metricbeats


These Beats allow us to collect the following information from each machine:

 

Filebeats collects log files generated by your system or locations that we specify. Currently logs stored in /var/log/syslog from the monitored machines are being collected. Metricbeats collects data from the operating system. In our environment you can expect to see data related to the hosts name, architecture, OS name and version.


### Using the Playbook
In order to use the playbook, you will need to have an Ansible control node already configured. Assuming you have such a control node provisioned:

SSH into the control node and follow the steps below:
- Copy the ansible.cfg file to /etc/ansible.
- Update the remote_user to include the default user as “dockervm”.
- Run the playbook, and navigate to DVMz1 to check that the installation worked as expected.

The playbook is
The my-playbook.yml is the playbook. It needs to be stored into, /etc/ansible.


By navigating to the “hosts” file, /etc/ansible/hosts, we can group machines as needed. In our environment the web servers will have Filebeat and Metricbeats installed and are labeled “webservers” in the hosts file. The elk server is in a separate group labeled “elkservers”.


The URL you navigate to in order to check that the ELK server is running: 52.186.171.212:5601

_
